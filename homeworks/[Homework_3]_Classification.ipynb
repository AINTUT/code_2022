{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Homework 3] Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv49axWeylsB"
      },
      "source": [
        "This notebook is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/).\n",
        "\n",
        "Author: 蘇嘉冠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na0_QjevL_F5"
      },
      "source": [
        "# [Homework 3] Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxVfmTuzLmyp"
      },
      "source": [
        "## 展示題：鳶尾屬花卉分類（Binary Classification）\n",
        "\n",
        "我們蒐集到了鳶尾屬花卉的資料集（[來源](https://archive.ics.uci.edu/ml/datasets/iris)），想要從某朵花的兩個 feature，來預測這朵花的種類。\n",
        "\n",
        "我們將這個資料集的 csv 檔讀入至一個 pandas 的 DataFrame：`df`。資料的各個 column 的意義如下：\n",
        "- `petal length`：花瓣長度\n",
        "- `sepal length`：花萼長度\n",
        "- `type`：花的種類，有 3 種可能\n",
        "    - `Iris-setosa`（山鳶尾）\n",
        "    - `Iris-versicolor`（變色鳶尾）\n",
        "    - `Iris-virginica`（維吉尼亞鳶尾）\n",
        "\n",
        "現在我們要做的是 Binary Classification，目標為：\n",
        "- `Iris-setosa`：label 為 `0`\n",
        "- `Iris-versicolor`：label 為 `1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6tUTprCWdhH"
      },
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTwytnL7Wp8N"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/AINTUT/code_2022/main/datasets/iris.csv\",\n",
        ")\n",
        "\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjy_aNuyv9B2"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLk8qbi8v-It"
      },
      "source": [
        "讀取原始資料後，我們需要先將 input x 與 output y 根據他們需要的 feature，將資料分別取出。\n",
        "\n",
        "由於 y 的資料有包含我們不需要的目標（`Iris-virginica`），因此必須要其剔除。剔除後我們還要將所有 `Iris-setosa` 的值轉換成 `0`，`Iris-versicolor` 的值轉換成 `1`，才能給接下來的訓練使用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9uhMS8kZILz"
      },
      "source": [
        "# Features for x.\n",
        "input_features = [\n",
        "    \"petal length\",\n",
        "    \"sepal length\",\n",
        "]\n",
        "# The feature for y.\n",
        "output_feature = \"type\"\n",
        "# The labels to be predicted.\n",
        "labels = [\n",
        "    \"Iris-setosa\",\n",
        "    \"Iris-versicolor\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDvideHxZgYM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get rows that belong to our target labels.\n",
        "data = df[df[output_feature] != \"Iris-virginica\"]\n",
        "\n",
        "# Collect data values for input x.\n",
        "x_data = data[input_features].to_numpy()\n",
        "print(x_data)\n",
        "print(x_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coleccte data values for output y, and convert it to the format for\n",
        "# classification.\n",
        "y_data = data[output_feature]\n",
        "print(y_data)\n",
        "y_data = np.where(y_data == labels[0], 0, 1)\n",
        "print(y_data)\n",
        "print(y_data.shape)"
      ],
      "metadata": {
        "id": "HBbSaT3CMj2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fUi7RvxJDC"
      },
      "source": [
        "接下來，將資料分割成 training data 與 testing data，比例為 70:30。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSiRTXIobwhr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing data.\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data,\n",
        "    y_data,\n",
        "    test_size=0.3,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dIBPN1GxQLD"
      },
      "source": [
        "再來我們用 standardization 對資料做 feature scaling。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx-MPScVcG2j"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Apply feature scaling on input x.\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_std = scaler.transform(x_train)\n",
        "x_test_std = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwVmAGpFxoQA"
      },
      "source": [
        "### Data Visualization\n",
        "\n",
        "這一步驟會來視覺化我們的資料！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyiOHNfgz5n2"
      },
      "source": [
        "由於我們想要同時視覺化 training data 與 testing data，因此用另外的變數把這兩部份的資料合起來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Au7ehucQgs"
      },
      "source": [
        "# Combine the scaled training and testing, they are only used for visualization.\n",
        "x_combined_std = np.vstack((x_train_std, x_test_std))\n",
        "y_combined = np.hstack((y_train, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncs4zn8kyDKg"
      },
      "source": [
        "這裡的視覺化最重要的是看各筆資料在兩個 input features 下的分佈狀態，以及每筆資料的 label，因此我們定義了 `plot_data()` 這個 function 來達到目標。另外，如果也提供 `classifier` 給這個 function的話（晚點會用到），還可以同時把分類的 decision boundary 畫出來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjmGZ97vckBu"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_data(x, y, labels, input_features, classifier=None, resolution=0.02):\n",
        "    # Setup marker generator and color map\n",
        "    colors = (\n",
        "        \"green\",\n",
        "        \"red\",\n",
        "        \"lightgreen\",\n",
        "    )\n",
        "    markers = (\n",
        "        \"x\",\n",
        "        \"s\",\n",
        "        \"o\",\n",
        "    )\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    # Plot the decision surface if classifier exists.\n",
        "    if classifier is not None:\n",
        "        x1_min, x1_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
        "        x2_min, x2_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
        "        xx1, xx2 = np.meshgrid(\n",
        "            np.arange(x1_min, x1_max, resolution),\n",
        "            np.arange(x2_min, x2_max, resolution),\n",
        "        )\n",
        "        z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "        z = z.reshape(xx1.shape)\n",
        "        plt.contourf(xx1, xx2, z, alpha=0.4, cmap=cmap)\n",
        "        plt.xlim(xx1.min(), xx1.max())\n",
        "        plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    # plot class samples\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(\n",
        "            x=x[y == cl, 0],\n",
        "            y=x[y == cl, 1],\n",
        "            alpha=0.8,\n",
        "            color=cmap(idx),\n",
        "            marker=markers[idx],\n",
        "            label=labels[cl],\n",
        "        )\n",
        "\n",
        "    plt.xlabel(input_features[0] + \"[standardalized]\")\n",
        "    plt.ylabel(input_features[1] + \"[standardalized]\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWe_jKiAc_aR"
      },
      "source": [
        "# Visualize the data.\n",
        "plot_data(x_combined_std, y_combined, labels, input_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2seYG-x0n6E"
      },
      "source": [
        "## Training\n",
        "\n",
        "我們直接使用 scikit-learn 的 [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) 來做分類的訓練。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq6eLfUX1bLu"
      },
      "source": [
        "首先，我們先創建一個型別為 `LogisticRegression ` 的物件，作為我們的 classifier（分類器），其中參數的意義為：\n",
        "- `multi_class=\"multinomial\"`：設定loss function 為 Cross Entropy\n",
        "- `solver=\"sag\"`：一種 Gradient Descent 的變化方法\n",
        "- `C=1000.0`：Regularization 的程度，越小則代表程度越強\n",
        "- `random_state=0`：由於 `sag` 有隨機性，因此我們填入固定的值讓同樣的結果可以重現\n",
        "\n",
        "創建了 classifier 後，我們再用它 `fit()` 這個 method 來做訓練。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KG2Ba15eEX6"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a classifier by using Logistic Regression.\n",
        "classifier = LogisticRegression(\n",
        "    multi_class=\"multinomial\",\n",
        "    solver=\"sag\",\n",
        "    C=1000.0,\n",
        "    random_state=0,\n",
        ")\n",
        "# Train the classifier.\n",
        "classifier.fit(x_train_std, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-I8hWvt3K6w"
      },
      "source": [
        "訓練好之後，我們可以分別用 classifier 的 `predict_proba()` 與 `predict()` 來預測給定資料的機率與 label。下面是預測 testing data 前 3 筆資料的範例。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5-_1s7IfOwv"
      },
      "source": [
        "# Predict the probabilities for the first three testing examples.\n",
        "probabilities = classifier.predict_proba(x_test_std[:3, :])\n",
        "print(probabilities)\n",
        "\n",
        "# Predict the labels for the first three testing examples.\n",
        "predictions = classifier.predict(x_test_std[:3, :])\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_24W22P4D_o"
      },
      "source": [
        "我們來視覺化訓練結果，除了資料外，我們也將 `classifier` 丟進 `plot_data()`，因此會同時把分類的 decision boundary 畫出來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbmJCtn5gERg"
      },
      "source": [
        "# Visualize the data with classification results.\n",
        "plot_data(x_combined_std, y_combined, labels, input_features, classifier=classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6_ub8yO4pKW"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "最後一部分，我們想要了解訓練的結果在 testing data 下表現如何。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4qHbxzO5ZBp"
      },
      "source": [
        "這裡我們用 classifier 來預測所有 testing data 的 label。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPqB5BEhfph"
      },
      "source": [
        "# Predict the labels for all testing examples.\n",
        "y_pred = classifier.predict(x_test_std)\n",
        "print(y_pred)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F877_paS5z9m"
      },
      "source": [
        "我們想要得到預測結果的 confusion matrix，因此使用 scikit-learn 的 `confusion_matrix()` 來達成。要注意的是，Scikit-Learn 回傳的 confusion matrix 的順序如下，跟我們在投影片上的順序不一樣。\n",
        "\n",
        "![](https://i.imgur.com/HQsqjR1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSOzztuQi1hd"
      },
      "source": [
        "def plot_confusion_matrix(conf_mat):\n",
        "    plt.matshow(conf_mat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "\n",
        "    for idx_true in range(conf_mat.shape[0]):\n",
        "        for idx_pred in range(conf_mat.shape[0]):\n",
        "            plt.text(\n",
        "                x=idx_pred,\n",
        "                y=idx_true,\n",
        "                s=conf_mat[idx_true, idx_pred],\n",
        "                va=\"center\",\n",
        "                ha=\"center\",\n",
        "            )\n",
        "\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"Actual Label\")\n",
        "\n",
        "    plt.show()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1xmbD3xi97L"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Construct the confusion matrix.\n",
        "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "print(conf_mat)\n",
        "\n",
        "# Visualize the confusion matrix.\n",
        "plot_confusion_matrix(conf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRR9v_qG6cMd"
      },
      "source": [
        "最後的最後，我們使用 scikit-learn 的 `precision_score`, `recall_score` 以及 `f1_score` 來計算預測結果的 Precsion, Recall 以及 F1 Score。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjmePZeZq3-u"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calculate precision, recall and f1 score.\n",
        "precision = precision_score(y_true=y_test, y_pred=y_pred)\n",
        "recall = recall_score(y_true=y_test, y_pred=y_pred)\n",
        "f1 = f1_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(\"Precision = {}\".format(precision))\n",
        "print(\"Recall = {}\".format(recall))\n",
        "print(\"F1 Score = {}\".format(f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkqHyd8y79cl"
      },
      "source": [
        "## 題組（一）：鳶尾屬花卉分類（Binary Classification）II\n",
        "\n",
        "如果將 Binary Classification 的目標改成：\n",
        "- `Iris-versicolor`：label 為 `0`\n",
        "- `Iris-virginica`：label 為 `1`\n",
        "\n",
        "請修改展示題的程式碼，並且求出訓練後的：\n",
        "- Precision 為多少？（`versi_virgin_precision`）\n",
        "- Recall 為多少？（`versi_virgin_recall`）\n",
        "- F1 Score 為多少？（`versi_virgin_f1`）"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE MODIFY CODE BELOW\n",
        "versi_virgin_precision = 0.0\n",
        "versi_virgin_recall = 0.0\n",
        "versi_virgin_f1 = 0.0\n",
        "\n",
        "print(\"Precision = {}\".format(versi_virgin_precision))\n",
        "print(\"Recall = {}\".format(versi_virgin_recall))\n",
        "print(\"F1 Score = {}\".format(versi_virgin_f1))"
      ],
      "metadata": {
        "id": "gpYzrsTxWVWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFnR9aAb-C9k"
      },
      "source": [
        "## 題組（二）：鳶尾屬花卉分類（Multi-Class Classification）\n",
        "\n",
        "如果我們改成 Multi-Class Classification，目標為：\n",
        "- `Iris-setosa`：label 為 `0`\n",
        "- `Iris-versicolor`：label 為 `1`\n",
        "- `Iris-virginica`：label 為 `2`\n",
        "\n",
        "請修改展示題的程式碼，並且求出訓練完成後：\n",
        "- 若只考慮 `Iris-virginica` 的狀況下（亦即將 `Iris-virginica` 視為為 Positive，其他視為 Negative），則 Precision 為多少？（`virgin_only_precision`）\n",
        "    - 提示：在使用 [precision_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) 的時候，需要加入一個參數 `average`\n",
        "- 模型整體的 Macro Precision 為多少？Macro Precision 的定義如附註（`macro_precision`）\n",
        "    - 提示：在使用 [precision_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) 的時候，需要加入一個參數 `average`\n",
        "\n",
        "附註：Macro Precision 的算法\n",
        "\n",
        "對於各個 label，先分別計算在只考慮該 label 的狀況下的 Precision 值，再把各個 label 的 Precision 做平均，得到 Macro Precision。\n",
        "\n",
        "$Precision_{macro} = \\frac{Precision_{1} + ... + Precision_{k}}{k}$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE MODIFY CODE BELOW\n",
        "virgin_only_precision = 0.0\n",
        "macro_precision = 0.0\n",
        "\n",
        "print(\"Precision for Virginica only = {}\".format(virgin_only_precision))\n",
        "print(\"Macro Precision = {}\".format(macro_precision))"
      ],
      "metadata": {
        "id": "pMVBaffcXlfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 答案上傳區\n",
        "\n",
        "三區塊的功能分別如下：\n",
        "1. 請將 `sid` 改為你的學號、`credential` 改為你收到的密碼\n",
        "2. 執行上傳答案的程式，提交後你會看到這次上傳的每一題答案是否正確（`PASS` 為答對，`FAIL` 為答錯）\n",
        "3. 查看你所有作業的答題狀況"
      ],
      "metadata": {
        "id": "8vU32eYMUMv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sid = \"\" # PLEASE MODIFY\n",
        "credential = \"\" # PLEASE MODIFY"
      ],
      "metadata": {
        "id": "bx6mumsTUNTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "def submit_answers(\n",
        "    sid,\n",
        "    credential,\n",
        "    ordinal,\n",
        "    answers,\n",
        "    api_url=\"https://aintut2022.herokuapp.com\",\n",
        "    api_version=\"v1\",\n",
        "):\n",
        "    request_url = \"{}/{}/assignments\".format(api_url, api_version)\n",
        "\n",
        "    res = requests.post(request_url, data={\n",
        "        \"sid\": sid,\n",
        "        \"credential\": credential,\n",
        "        \"ordinal\": ordinal,\n",
        "        \"answers\": answers,\n",
        "    })\n",
        "\n",
        "    data = res.json()\n",
        "\n",
        "    if res.status_code >= 400:\n",
        "        print(\"\\x1b[31m{}\\x1b[0m\".format(json.dumps(data, indent=4)))\n",
        "        return\n",
        "\n",
        "    correctnesses = data[\"correctnesses\"]\n",
        "    for answer, correctness in zip(answers, correctnesses):\n",
        "        passd_text = \\\n",
        "            \"[\\033[92mPASS\\x1b[0m]\" if correctness else \"[\\x1b[31mFAIL\\x1b[0m]\"\n",
        "        print(\"{} Your answer: {}\".format(passd_text, answer))\n",
        "\n",
        "answers = [\n",
        "    versi_virgin_precision,\n",
        "    versi_virgin_recall,\n",
        "    versi_virgin_f1,\n",
        "    virgin_only_precision,\n",
        "    macro_precision,\n",
        "]\n",
        "\n",
        "submit_answers(sid, credential, 3, answers)"
      ],
      "metadata": {
        "id": "yArPqFokUQSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "def query_assignments(\n",
        "    sid,\n",
        "    credential,\n",
        "    api_url=\"https://aintut2022.herokuapp.com\",\n",
        "    api_version=\"v1\",\n",
        "):\n",
        "    request_url = \"{}/{}/assignments\".format(api_url, api_version)\n",
        "\n",
        "    res = requests.get(request_url, params={\n",
        "        \"sid\": sid,\n",
        "        \"credential\": credential,\n",
        "    })\n",
        "\n",
        "    data = res.json()\n",
        "\n",
        "    if res.status_code >= 400:\n",
        "        print(\"\\x1b[31m{}\\x1b[0m\".format(json.dumps(data, indent=4)))\n",
        "        return\n",
        "\n",
        "    assignments = sorted(data, key=lambda d: d[\"ordinal\"])\n",
        "\n",
        "    for assignment in assignments:\n",
        "        ordinal = assignment[\"ordinal\"]\n",
        "        correctnesses = \" \".join([\n",
        "            \"\\033[92mPASS\\x1b[0m\" if c else \"\\x1b[31mFAIL\\x1b[0m\"\n",
        "            for c in assignment[\"correctnesses\"]\n",
        "        ])\n",
        "        print(\"Assignment {}: {}\".format(ordinal, correctnesses))\n",
        "\n",
        "\n",
        "query_assignments(sid, credential)"
      ],
      "metadata": {
        "id": "Otd6FjJ2UTb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}