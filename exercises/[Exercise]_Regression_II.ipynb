{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Exercise] Regression II.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv49axWeylsB"
      },
      "source": [
        "This notebook is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/).\n",
        "\n",
        "Author: 蘇嘉冠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na0_QjevL_F5"
      },
      "source": [
        "# [Exercise] Regression II\n",
        "\n",
        "**小提示：由於開始變得複雜，可以先了解練習中各個 function 用來做什麼、如何使用的就好，有空有興趣再了解實做細節**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e75HmxuUENW8"
      },
      "source": [
        "## 展示題（一）：房價預測（non-linearity 版本）\n",
        "\n",
        "我們蒐集到了波士頓郊區的房價資料集（[來源](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/?C=N;O=D)），想要從某城鎮的一個 feature，加上 non-linearity，來預測該城鎮自用住宅的房價中位數（`MEDV`）。\n",
        "\n",
        "我們將這個資料集的 csv 檔讀入至一個 pandas 的 DataFrame：`df`。資料的各個 column 的意義如下：\n",
        "- `CRIM`：某城鎮的人均犯罪率\n",
        "- `ZN`：「超過 25,000 平方呎的住宅用地區塊」所佔的比例\n",
        "- `INDUS`：某城鎮「非零售的商業用地」比例（英畝）\n",
        "- `NOX`：一氧化氮濃度（以 10 ppm 為單位）\n",
        "- `RM`：平均每戶有幾個房間\n",
        "- `AGE`： 1940 年之前所建的房屋，屋主自用的比例\n",
        "- `DIS`：到波士頓五個就業服務中心的（加權）距離\n",
        "- `RAD`：使用高速公路的方便性 / 可達性指數\n",
        "- `TAX`：「總價 / 房屋稅」的比例（單位：10,000 美金）\n",
        "- `PTRATIO`：某城鎮的「生 / 師」比\n",
        "- `LSTAT`：低所得的人口比例\n",
        "- `MEDV`：自用住宅的房價中位數（單位：1,000 美金）\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJA285HdE5sV"
      },
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DONtW1BM81Z9"
      },
      "source": [
        "### 讀取資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qFffL07R8k5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/AINTUT/code_2022/main/datasets/\"\n",
        "    \"house_pricing.csv\",\n",
        ")\n",
        "\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZinCHRs9rT8"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "我們定義了 3 個 function 來做資料前處理：\n",
        "- `create_scaler()`：用 standardization 來對某批資料做 feature scaling，並回傳一個型別為 `StandardScaler` 的物件，這個物件儲存著某批資料的的平均值、標準差\n",
        "- `apply_nonlinear()`：將某資料做 non-linearity，程度根據 `degree` 決定，例如 `degree` 為 3 的時候，代表會產生包含 1 次方、2 次方、3 次方的資料\n",
        "- `preprocess_data()`：先對資料做 feature scaling，再做 non-linearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVonF8nC9g92"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def create_scaler(data):\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit_transform(data)\n",
        "\n",
        "    return scaler\n",
        "\n",
        "def apply_nonlinear(data, degree):\n",
        "    data_stacks = []\n",
        "    for data_index in range(data.shape[1]):\n",
        "        for degree_index in range(1, degree + 1):\n",
        "            degree_data = data[:, data_index] ** degree_index\n",
        "            data_stacks.append(degree_data)\n",
        "    applied_data = np.stack(data_stacks, axis=1)\n",
        "\n",
        "    return applied_data\n",
        "\n",
        "def preprocess_data(data, scaler, degree):\n",
        "    applied_data = scaler.transform(data)\n",
        "    applied_data = apply_nonlinear(applied_data, degree)\n",
        "\n",
        "    return applied_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71UhmCrQ8pCY"
      },
      "source": [
        "### Training 與 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msbubkW380kh"
      },
      "source": [
        "首先我們定義了 3 個關於 training 的 function：`predict()`、`calculate_loss` 以及 `fit()`，基本上內容都跟上次的練習（Regression I）一樣，主要差別在：\n",
        "1. 我們現在資料的 input feature 超過 1 個\n",
        "2. `fit()` 加上了 `regular_lambda` 這個參數，代表 loss function 的 regularization 的 λ 值（如果 `regular_lambda` = 0 則代表不加 regularization）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZMjloH4_txP"
      },
      "source": [
        "def predict(x, weights):\n",
        "    return np.dot(x, weights[1:]) + weights[0]\n",
        "\n",
        "def calculate_loss(y_gt, y_pred, weights, regular_lambda):\n",
        "    loss = \\\n",
        "        ((y_gt - y_pred) ** 2).sum() / 2.0 \\\n",
        "        + regular_lambda * (weights ** 2).sum()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def fit(x_train, y_train, epoches, learning_rate, regular_lambda):\n",
        "    weights = np.zeros(x_train.shape[1] + 1)\n",
        "    losses = []\n",
        "\n",
        "    for _ in range(epoches):\n",
        "        y_pred = predict(x_train, weights)\n",
        "\n",
        "        diff = y_train - y_pred\n",
        "        weights[0] = weights[0] - learning_rate * -diff.sum()\n",
        "        weights[1:] = \\\n",
        "            weights[1:] \\\n",
        "            - learning_rate \\\n",
        "            * (-x_train.T.dot(diff) + 2 * regular_lambda * weights[1:])\n",
        "\n",
        "        losses.append(calculate_loss(y_train, y_pred, weights, regular_lambda))\n",
        "\n",
        "    return weights, losses"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7dq3Y5rAll1"
      },
      "source": [
        "再來我們定義 2 個關於 evaluation 的 function，其中 `reg_plot()` 同上次練習（Regression I），而 `predict_raw()` 類似 `predict()`。差別在於 `predict()` 是對已經預處理過得資料做預測，`predict_raw()` 則是對沒有預處理的資料做預測。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6D4we4rAsQd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_raw(x, scaler, degree, weights):\n",
        "    preprocessed_x = preprocess_data(x, scaler, degree)\n",
        "    y_pred = predict(preprocessed_x, weights)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "def reg_plot(x_gt, y_gt, x_fit, y_fit):\n",
        "    plt.scatter(x_gt[:, 0], y_gt, c=\"steelblue\", edgecolor=\"white\")\n",
        "    plt.plot(x_fit[:, 0], y_fit, c=\"black\")\n",
        "\n",
        "    plt.xlabel(\"RM\")\n",
        "    plt.ylabel(\"MEDV\")\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPn5ZAHiCXHK"
      },
      "source": [
        "接下來我們用 1 個 function 來跑 training 與 evaluation 的流程：\n",
        "1. 呼叫 `preprocess_data()` 來對資料做預處理\n",
        "2. 呼叫 `fit()` 來做訓練，得到訓練結果\n",
        "3. 將每個 epoch 的 loss 畫成圖\n",
        "4. 將 training data 的結果畫成圖\n",
        "5. 計算 training data 的 MSE\n",
        "6. 將 testing data 的結果畫成圖\n",
        "7. 計算 testing data 的 MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioEQ8QANVy6J"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def run(\n",
        "    x_train,\n",
        "    x_test,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    degree,\n",
        "    epoches,\n",
        "    learning_rate,\n",
        "    regular_lambda=0,\n",
        "    show_fit=True,\n",
        "):\n",
        "    scaler = create_scaler(x_train)\n",
        "\n",
        "    x_train_std = preprocess_data(x_train, scaler, degree)\n",
        "    x_test_std = preprocess_data(x_test, scaler, degree)\n",
        "\n",
        "    weights, losses = fit(\n",
        "        x_train_std,\n",
        "        y_train,\n",
        "        epoches,\n",
        "        learning_rate,\n",
        "        regular_lambda,\n",
        "    )\n",
        "\n",
        "    plt.plot(range(1, epoches + 1), losses)\n",
        "    plt.ylabel(\"SSE\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Losses (degree = {}, regular_lambda = {})\".format(\n",
        "        degree,\n",
        "        regular_lambda,\n",
        "    ))\n",
        "\n",
        "    if show_fit and (x_train.shape[1] == 1):\n",
        "        x_fit = np.arange(x_train.min(), x_train.max(), 0.1)[:, np.newaxis]\n",
        "        y_fit = predict_raw(x_fit, scaler, degree, weights)\n",
        "        reg_plot(x_train, y_train, x_fit, y_fit)\n",
        "\n",
        "    y_pred = predict(x_train_std, weights)\n",
        "    mse_train = mean_squared_error(y_train, y_pred)\n",
        "    print(\"MSE of Training Data (degree = {}, regular_lambda = {}): {}\".format(\n",
        "        degree,\n",
        "        regular_lambda,\n",
        "        mse_train,\n",
        "    ))\n",
        "\n",
        "    if show_fit and (x_train.shape[1] == 1):\n",
        "        x_fit = np.arange(x_test.min(), x_test.max(), 0.1)[:, np.newaxis]\n",
        "        y_fit = predict_raw(x_fit, scaler, degree, weights)\n",
        "        reg_plot(x_test, y_test, x_fit, y_fit)\n",
        "\n",
        "    y_pred = predict(x_test_std, weights)\n",
        "    mse_test = mean_squared_error(y_test, y_pred)\n",
        "    print(\"MSE of Testing Data (degree = {}, regular_lambda = {}): {}\".format(\n",
        "        degree,\n",
        "        regular_lambda,\n",
        "        mse_test,\n",
        "    ))\n",
        "\n",
        "    return mse_train, mse_test"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XQjXtKHEX2B"
      },
      "source": [
        "接下來我們實際跑 training 與 evaluation 的流程，重複好幾次，並且將每次得到的 MSE 紀錄下來。\n",
        "\n",
        "每一次最主要的差別在於 non-linearity 的程度，程度從 1 到 5（1 代表沒有 non-linearity，5 代表會對 input feature 做 1 次方到 5 次方的轉換）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JB4Ap58qC59"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "hyper_parameters = [\n",
        "    (1, 20, 0.001),\n",
        "    (2, 60, 0.001),\n",
        "    (3, 180, 0.0001),\n",
        "    (4, 1800, 0.00001),\n",
        "    (5, 15000, 0.000001),\n",
        "]\n",
        "\n",
        "x_data = df[[\"RM\"]].to_numpy()\n",
        "y_data = df[\"MEDV\"].to_numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data,\n",
        "    y_data,\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "mse_train_list = []\n",
        "mse_test_list = []\n",
        "\n",
        "for hyper_parameter in hyper_parameters:\n",
        "    degree, epoches, learning_rate = hyper_parameter\n",
        "    mse_train, mse_test = \\\n",
        "        run(x_train, x_test, y_train, y_test, degree, epoches, learning_rate)\n",
        "\n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3T6g3odGc2i"
      },
      "source": [
        "最後我們將不同 non-linearity 程度下 MSE 的圖畫出來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2gfiSsIFvw8"
      },
      "source": [
        "def mse_degrees_plot(degrees, mse_train_list, mse_test_list):\n",
        "    plt.plot(degrees, mse_train_list, c=\"green\", label=\"Training Data\")\n",
        "    plt.plot(degrees, mse_test_list, c=\"red\", label=\"Testing Data\")\n",
        "\n",
        "    plt.xticks(degrees)\n",
        "\n",
        "    plt.xlabel(\"Degree\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.plot()\n",
        "\n",
        "degrees = [p[0] for p in hyper_parameters]\n",
        "mse_degrees_plot(degrees, mse_train_list, mse_test_list)\n",
        "\n",
        "print(\"Degree\\tTraining MSE\\t\\tTesting MSE\")\n",
        "for degree, mse_train, mse_test in zip(degrees, mse_train_list, mse_test_list):\n",
        "    print(\"{}\\t{}\\t{}\".format(degree, mse_train, mse_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cBfL3iIG5df"
      },
      "source": [
        "## 展示題（二）：房價預測（多變數版本）\n",
        "\n",
        "我們現在考慮不只一個 input feature 的情況，並且去試著找到最好的 input feature 有哪些。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S8VQXSMJjKw"
      },
      "source": [
        "首先，我們先選出 5 個與預測的目標：房價（`MEDV`）最有關係的 feature，並且分別畫出這 5 個 feature 與房價之間的散佈圖。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFGrFBe0JUlT"
      },
      "source": [
        "features = [\"RM\", \"LSTAT\", \"PTRATIO\", \"INDUS\", \"TAX\"]\n",
        "\n",
        "for feature in features:\n",
        "    df.plot.scatter(x=feature, y=\"MEDV\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk8_Ave3J-89"
      },
      "source": [
        "接下來我們實際跑 training 與 evaluation 的流程，重複好幾次，並且將每次得到的 MSE 紀錄下來。每一次最主要的差別在於 input feature 的數量，從 1 個到 5 個。\n",
        "\n",
        "附註：由於我們在前面的展示題（一）得知程度為 3 的 non-linearity 是最好的，因此沿用這個設定。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzKGVPx-TShL"
      },
      "source": [
        "degree = 3\n",
        "epoches = 180\n",
        "learning_rate = 0.0001\n",
        "\n",
        "mse_train_list = []\n",
        "mse_test_list = []\n",
        "\n",
        "for num_features in range(1, len(features) + 1):\n",
        "    selected_features = features[0:num_features]\n",
        "    x_data = df[selected_features].to_numpy()\n",
        "    y_data = df[\"MEDV\"].to_numpy()\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        x_data,\n",
        "        y_data,\n",
        "        test_size=0.2,\n",
        "        random_state=0,\n",
        "    )\n",
        "\n",
        "    print(\"=== Selected features: {} ===\".format(selected_features))\n",
        "    mse_train, mse_test = run(\n",
        "        x_train,\n",
        "        x_test,\n",
        "        y_train,\n",
        "        y_test,\n",
        "        degree,\n",
        "        epoches,\n",
        "        learning_rate,\n",
        "        show_fit=False,\n",
        "    )\n",
        "    print(\"\")\n",
        "\n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaM_e1ghKqP6"
      },
      "source": [
        "最後我們將不同 input feature 數量下 MSE 的結果秀出來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktv65QrRHG2s"
      },
      "source": [
        "print(\"# of Features\\tTraining MSE\\t\\tTesting MSE\")\n",
        "for index in range(len(features)):\n",
        "    num_features = index + 1\n",
        "    selected_features = features[0:num_features]\n",
        "    mse_train = mse_train_list[index]\n",
        "    mse_test = mse_test_list[index]\n",
        "\n",
        "    print(\"{}\\t\\t{}\\t{}\".format(num_features, mse_train, mse_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvLH9j6YK1CU"
      },
      "source": [
        "## 展示題（三）：房價預測（regularization）\n",
        "\n",
        "在做展示題（一）跟（二）的時候都沒有加上 regularization（λ 值為 0）。現在我們來看看加入 regularization 對結果的影響"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5kipkAKLjWG"
      },
      "source": [
        "我們實際跑 training 與 evaluation 的流程，重複好幾次，並且將每次得到的 MSE 紀錄下來。每一次最主要的差別在於 λ 值的不同，從 0 個到 128。\n",
        "\n",
        "附註：由於我們在前面的展示題（一）跟（二）得知，程度為 3 的 non-linearity 加上 input feature 為 `RM` + `LSTAT` 是最好的，因此沿用這個設定。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPVl9uJqpeJq"
      },
      "source": [
        "regular_lambdas = [0, 1, 2, 4, 8, 16, 32, 64, 128]\n",
        "\n",
        "degree = 3\n",
        "epoches = 180\n",
        "learning_rate = 0.0001\n",
        "\n",
        "features = [\"RM\", \"LSTAT\"]\n",
        "\n",
        "mse_train_list = []\n",
        "mse_test_list = []\n",
        "\n",
        "for regular_lambda in regular_lambdas:\n",
        "    x_data = df[features].to_numpy()\n",
        "    y_data = df[\"MEDV\"].to_numpy()\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        x_data,\n",
        "        y_data,\n",
        "        test_size=0.2,\n",
        "        random_state=0,\n",
        "    )\n",
        "\n",
        "    mse_train, mse_test = run(\n",
        "        x_train,\n",
        "        x_test,\n",
        "        y_train,\n",
        "        y_test,\n",
        "        degree,\n",
        "        epoches,\n",
        "        learning_rate,\n",
        "        regular_lambda=regular_lambda,\n",
        "        show_fit=False,\n",
        "    )\n",
        "\n",
        "    mse_train_list.append(mse_train)\n",
        "    mse_test_list.append(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J712cbuNL7km"
      },
      "source": [
        "最後我們將不同 λ 值下 MSE 的結果秀出來。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoLjGLWIrxB"
      },
      "source": [
        "def mse_regular_plot(regular_lambdas, mse_train_list, mse_test_list):\n",
        "    plt.plot(regular_lambdas, mse_train_list, c=\"green\", label=\"Training Data\")\n",
        "    plt.plot(regular_lambdas, mse_test_list, c=\"red\", label=\"Testing Data\")\n",
        "\n",
        "    plt.xticks(regular_lambdas)\n",
        "    plt.xscale(\"log\", basex=2)\n",
        "\n",
        "    plt.xlabel(\"Lambda for Regularization\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "    plt.plot()\n",
        "\n",
        "mse_regular_plot(regular_lambdas, mse_train_list, mse_test_list)\n",
        "\n",
        "print(\"Regular Lambda\\tTraining MSE\\t\\tTesting MSE\")\n",
        "for regular_lambda, mse_train, mse_test in \\\n",
        "    zip(regular_lambdas, mse_train_list, mse_test_list):\n",
        "    print(\"{}\\t\\t{}\\t{}\".format(regular_lambda, mse_train, mse_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "features = [\"RM\", \"LSTAT\"]\n",
        "degree = 3\n",
        "\n",
        "x_data = df[features].to_numpy()\n",
        "y_data = df[\"MEDV\"].to_numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data,\n",
        "    y_data,\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "x_train = apply_nonlinear(x_train, degree)\n",
        "x_test = apply_nonlinear(x_test, degree)\n",
        "\n",
        "lr = Ridge()\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(x_train)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "\n",
        "print(\"MSE of Training Data: {}\".format(mse))\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"MSE of Testing Data: {}\".format(mse))"
      ],
      "metadata": {
        "id": "NLdbH6u8XCfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzjAzQAixLq9"
      },
      "source": [
        "## 練習題\n",
        "\n",
        "試著用 `scikit-learn` 的[Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)，input features 為 `RM` 加上 `LSTAT`，degree 為 3，來做一次訓練\n",
        "- Ridge 的用法類似於 LinearRegression，請參考[上次的練習（Regression I）](https://colab.research.google.com/drive/15fTirCx1ejkr_K-cghE5rRBkRNqSGa-C?usp=sharing)，`改用 Scikit-Learn 做 Training` 這部份"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "附上參考答案，可以先自己試試後再看答案"
      ],
      "metadata": {
        "id": "JFKP1zfmerbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "features = [\"RM\", \"LSTAT\"]\n",
        "degree = 3\n",
        "\n",
        "x_data = df[features].to_numpy()\n",
        "y_data = df[\"MEDV\"].to_numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data,\n",
        "    y_data,\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "x_train = apply_nonlinear(x_train, degree)\n",
        "x_test = apply_nonlinear(x_test, degree)\n",
        "\n",
        "lr = Ridge()\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(x_train)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "\n",
        "print(\"MSE of Training Data: {}\".format(mse))\n",
        "\n",
        "y_pred = lr.predict(x_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"MSE of Testing Data: {}\".format(mse))"
      ],
      "metadata": {
        "id": "7RchuhnOYgWP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}